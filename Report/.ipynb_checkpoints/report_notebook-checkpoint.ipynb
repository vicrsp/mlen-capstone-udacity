{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Project\n",
    "Victor São Paulo Ruela\n",
    "\n",
    "February 5th, 2019\n",
    "\n",
    "## I. Definition\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "Partial Discharge (PD) signals are electrical discharges that can occur inside the insulation of high voltage equipments. These signals have a repetitive nature and are confined to small regions, which in the long run can lead to irreparable damage to the equipment. Therefore, it is vital for the energy industry companies to monitor the occcurrance of PDs, in order to prevent accidents and guarantee a realiable energy transmission for its customers.\n",
    "\n",
    "Measuring these signals in the field is already very challenging task, due to its low intensity and high noise levels from high voltage systems. However, this is just one part of the problem: based on the measurements, how can we predict some of its characteristics, such as faults, the level of damage, local of occurrence and possible causes? These are tasks that can be achieve with signal processing techniques and machine learning algorithms.\n",
    "\n",
    "The dataset that is going to be used is available from the VSB Power Line Fault Detection Kaggle competition website:\n",
    "\n",
    "https://www.kaggle.com/c/vsb-power-line-fault-detection\n",
    "\n",
    "It contains several examples of labeled PD signals (fault or undamaged). Each signal contains 800,000 measurements of a power line's voltage, taken over 20 milliseconds for each one of the three phases.\n",
    "\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "The goal is to train a classification algorithm to predict for PD signal measurements if a power line damaged or not. I will be tackling this problem as a binary classification problem, also applying digital signal processing techniques to extract the most relevant features from the PD signals.\n",
    "\n",
    "The first task will be to apply signal processing techniques in order to remove the background noise from the measurements and obtain a clear representation of the partial discharge signals. This can be done using digital filters (Butterworth, Chebyschev, etc.), the Fourier Transform and the Discrete Wavelet Transform (DWT). After that, new features will be extracted, such as amount of PDs and the frequency-domain content. If necessary, more features can be include based on the thesis from the competition's responsible [1].\n",
    "\n",
    "For the training models, I pretend to compare binary classification models, such as Logistic Regression and Random Forests. I will work with simpler models in order to have more time available for the feature extraction, since this should be the most important taks on this porject. I expect to spend 70% of the time on the signal processing and feature extraction parts and 30% of the time on training models and tweaking parameters.\n",
    "\n",
    "### Metrics\n",
    "\n",
    "The results will be evaluated with the [Matthews correlation coefficient (MCC)](https://en.wikipedia.org/wiki/Matthews_correlation_coefficient) between the predicted and the observed response:\n",
    "\n",
    "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/5caa90fc15105b74b59a30bbc9cc2e5bd43a13b7 \"MCC\")\n",
    "\n",
    "where TP is the number of true positives, TN the number of true negatives, FP the number of false positives, and FN the number of false negatives. This is a very suitable metric, since the dataset is probably unbalanced because faults are not very frequent. \n",
    "\n",
    "This is the same metric used in the competition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Analysis\n",
    "\n",
    "### Data Exploration and Visualization\n",
    "\n",
    "The dataset is available at https://www.kaggle.com/c/vsb-power-line-fault-detection/data\n",
    "\n",
    "It contains the following files:\n",
    "\n",
    "a) metadata_[train/test].csv - The signal general information and labels. Contatins the following columns:\n",
    "\n",
    "* `id_measurement`: the ID code for a trio of signals recorded at the same time.\n",
    "\n",
    "* `signal_id`: the foreign key for the signal data. Each signal ID is unique across both train and test, so the first ID in train is '0' but the first ID in test is '8712'.\n",
    "\n",
    "* `phase`: the phase ID code within the signal trio. The phases may or may not all be \n",
    "impacted by a fault on the line.\n",
    "\n",
    "* `target`: 0 if the power line is undamaged, 1 if there is a fault.\n",
    "\n",
    "b) [train/test].parquet - The signal data. Each column contains one signal; 800,000 int8 measurements as exported with pyarrow.parquet version 0.11. More information about the parquet format can be found in https://acadgild.com/blog/parquet-file-format-hadoop.\n",
    "\n",
    "The metadata file is the link between the actual PD signals measurements in the parquet file and its label. For example, to access the signal with ID \"1\", you just need to load the column \"1\" from the .parquet file. This is actually a very interesting feature, because it allows to optimize the memory consumption by processing one signal at a time.\n",
    "\n",
    "The `metadata_train.csv` file contains `8712` rows, each one representing a signal available in the `train.parquet` file. The overall and per phase distribution for the labels are displayed in the figures below.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!---\n",
    "![Label distribution - per phase](train_data_dist.png \"Label distribution - per phase\")\n",
    "\n",
    "![Label distribution - Overall](train_data_dist_targets.png \"Label distribution - Overall\")\n",
    "\n",
    "-->\n",
    "\n",
    "![Label distribution - Overall](train_data_dist_twosided.png \"Label distribution - Overall\")\n",
    "\n",
    "\n",
    "We can clearly see the data is very unbalanced: only `6.0262%` of the data contains examples of fault signals. This was expected, since a fault event is not very common. Looking at the distribution considering the phase of the signal, we can see that the labels are evenly distributed among them. Therefore, phase should not be an input variable to the models, since it won't add any relevante information.\n",
    "\n",
    "Eah signal in the `train.parquet` contains `800,000` measurements of a power line's voltage, taken over `20` milliseconds. Thefore, the sampling rate is `40Mhz`. A sample signal PD signal for each phase can be seen in the figure below.\n",
    "\n",
    "![PD Signal](signal_phase_example.png \"PD Signal\")\n",
    "\n",
    "The figure below shows a comparison between a fault and normal example signals.\n",
    "![Fault and normal signals](signal_fault_normal_raw.png \"Fault and normal signals\")\n",
    "\n",
    "Based on these examples, the following can be inferred about PD signals:\n",
    "\n",
    "* There is a lot of background noise, which can be incorrectly identified as a PD pattern. Therefore, it is necessary to denoise this signal ass the first step for the analysis.\n",
    "* It's not easy to visually observe an actual PD pattern, since it happens very fast.\n",
    "* The start and end of the measuremente cycle is different depending on the phase.\n",
    "\n",
    "Moreover, the raw time-based data format should not be used for the machine learning algorithms, since this would lead to have `800,000` features as inputs to the model.Therefore, signal processing techniques will have to applied to extract features that can accurately represent the signal.\n",
    "\n",
    "\n",
    "### Algorithms and Techniques\n",
    "\n",
    "The following classifiers will be teste and the one with the highest cross-validation score on the dataset will be chosen: [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), [kNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and [Gradient Boosting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html). They are well known techniques for the binary classification task and are expected to perform well on this dataset, since they do not require very large datasets to work. They will be evaluated with their default pararemeters, as described in their documentation page.\n",
    "\n",
    "The chosen model will use as inputs the features extracted from the raw PD signals and the respective labels (see the `Data Preprocessing` section). A grid search will be executed in order to tune its hyperparameters and find the optimal classifier. For example, for the Random Forest, the following  hyperparameters can be optimized:\n",
    "\n",
    "* `n_estimators`: The number of trees in the forest\n",
    "* `max_features`: The number of features to consider when looking for the best split:\n",
    "* `max_depth`: The maximum depth of the tree\n",
    "* `min_samples_split`: The minimum number of samples required to split an internal node\n",
    "* `min_samples_leaf`: The minimum number of samples required to be at a leaf node\n",
    " \n",
    "### Benchmark\n",
    "\n",
    "The benchmark model will be a naive predictor that will output that the power line is always undamaged (false). Based on the data discussion from previous sections, this model will have `93.9738%` accuracy. This model will also have a baseline value of `0.0` for the Mathews Correlation Coefficient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Methodology\n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "#### Feature Extraction\n",
    "\n",
    "As discussed in the previous sections, signal processing techniques must be applied in order to extract the most relevant information from the signals. The first step is applying a filter to the signal in order to remove the background noise. An analysis of the most common PD denoising techniques is available in [2]. For this project, a high pass filter and a Discrete Wavelet Transform (DWT) denoising technique will be used.\n",
    "\n",
    "The high pass filter will remove all frequency content below a certain threshold. This is very important to remove the 50Hz baseline frequency from the power line, and also some low frequency noise. The threshold that is going to be used is 10kHz, since PD patterns are only observed above this value.\n",
    "\n",
    "The DWT is the most used signal processing technique for PD denoising, having several papers studying its application available in the literature. It works by decomposing the signal in several scales and levels based on a pre-selected mother Wavelet. The framework for PD denoising consists in:\n",
    "\n",
    "* Apply the DWT to the noisy signal until a decomposition level where its possible to distinguish the DP signal. This will calculate the wavelet coefficients $c$ for each level.\n",
    "* Chosse an appropriate threshold $T_{d}$ for selecting the coefficients for each level. This can be done either with soft or hard thresholding.\n",
    "* Recover the denoised signal using the inverse discrete Wavelet transform from the coefficients selected previously.\n",
    "\n",
    "A more detailed description regarding the Wavelet denoising framework can be found in [1,3]. For this project, the a hard-thresholding approach from [1] will be used. The limit $T_{d,j}$ is calculated based on the Mean Absolute Deviation (MAD), using the following equations: \n",
    "\n",
    "$$\\sigma = \\frac{1}{0.6745}~MAD(|c|) $$\n",
    "\n",
    "$$T_{d} = \\sigma\\sqrt{2\\log{n}} $$\n",
    "\n",
    "where $n$ is the lenght of the signal. The selected mother wavelet will be the `Debauchy 4`, since it was indicated in [2] as the most similar to the PD pattern.\n",
    "\n",
    "The high pass filter and DWT denoising will be applied for every signal in the database. After this step, we can start extracting new features to represente this signal. An filtered signal example can be seen in the figure below.\n",
    "\n",
    "![PD Signal Denoised](signal_phase_denoised.png \"PD Signal Denoised\")\n",
    "\n",
    "Afther that, time and frequency domain features will be extracted from the denoised signal. According to [4], the most relevant time domain features are:\n",
    "\n",
    "* Number of peaks\n",
    "* Mean width of peaks\n",
    "* Max width of peaks\n",
    "* Min width of peaks\n",
    "* Mean height of peaks\n",
    "* Max height of peaks\n",
    "* Min height of peaks\n",
    "\n",
    "The signal will be divided into 4 sections of size `200,000` and these features will be extracted for each subset, as suggested in [4]. This is done because the appearance of peaks are not random, i.e, they are clustered in specific subparts of the sinusoidal signal. This yields a total of 28 features extracted.\n",
    "\n",
    "In order to extract these features, the functions [find_peaks](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks.html) and [peak_widths](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.peak_widths.html#scipy.signal.peak_widths) from the `scipy` package will be used. It was necessary to fine tune the input parameters for both functions, and after several trials the following parameters were selected: \n",
    "\n",
    "1. **find_peaks**\n",
    "    * prominence: `10` (The prominence of a peak measures how much a peak stands out from the surrounding baseline of the signal and is defined as the vertical distance between the peak and its lowest contour line.)\n",
    " \n",
    "    * distance: `50` (Required minimal horizontal distance in samples between neighbouring peaks) \n",
    "\n",
    "2. **peak_widths**\n",
    "    * rel_height: `0.9` (Relative height at which the peak width is measured as a percentage of its prominence)\n",
    "\n",
    "In the following figures, it is possible to see the peaks from an example signal and also have a closer look at the width and height of a peak.\n",
    "\n",
    "![Signal Peaks](signal_peaks.png \"Signal Peaks\")\n",
    "\n",
    "![Peak height and width](signal_peak_zoom.png \"Peak height and width\")\n",
    "\n",
    "The frequency domain features are based on the power spectral density (PSD) of each denoised signal. The PSD will not be calculated based on the raw signal because the noise contamination in higher frequencies will introduce undesired bias to the data. The PSD will be split into 4 equals sections of 5 MHz (Nyquist frequency divided by 4), such that we can extract the following features from the signal at different frequency ranges:\n",
    "\n",
    "* Sum of power spectrum\n",
    "* Maximum value\n",
    "* Mean value\n",
    "\n",
    "This will be calculated with the [welch](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.signal.welch.html) function from the `scipy` package. Welch's method calculates an estimate of the power spectral density by dividing the data into overlapping segments, computing a modified periodogram for each segment and averaging the periodograms. An example for a faulted and normal signal can be seen in the figure below. This task yields more 16 extracted features.\n",
    "\n",
    "![Power spectral density](signal_fault_normal_psd_denoised.png \"Power spectral density\")\n",
    "\n",
    "After applying these two feature extraction, we finally have the dataset that is going to be used for training our prediction models. This dataset has 40 numerical features for each signal and their corresponding labels. \n",
    "\n",
    "\n",
    "#### Feature Transformation\n",
    "\n",
    "The dataset has features with very different magnitudes (e.g: number of peaks and peak width), therefore the dataset will first be normalized to the 0-1 range. The figure below shows the distribution of each feature after the normalization.\n",
    "\n",
    "![Scaled Features](dist_minmax_scaled.png \"Scaled Features\")\n",
    "\n",
    "It can be seen that almost all features distribution are skewed, which means the data does not follow a normal distribution. Therefore, the natural logarithm transformation is applied to the dataset.\n",
    "\n",
    "![Log-scaled Features](dist_minmax_scaled_log.png \"Log-scaled Features\")\n",
    "\n",
    "#### Feature Selection\n",
    "\n",
    "The next pre-processing step should be the feature selection using a tree-based approach. The idea behind this is that in every node in a decision tree is a condition is tested on a single feature, which is called the impurity. Thus, when training a tree, we can calculate how much each feature decreases the impurity in a tree. Finally, if we build an ensemble of trees, we can average these values on different subsets of the data and estimate the importance of the variables. For this task, the [ExtraTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html) model will be used. \n",
    "\n",
    "After applying this feature selection algorithm to the dataset, the importance of each feature can be seen in the figure below. \n",
    "\n",
    "![Feature Importance](feature_importances.png \"Feature Importance\")\n",
    "\n",
    "Based on this result, the following features will be selected for training the prediction models: `number_of_peaks_p1`, `number_of_peaks_p2`, `number_of_peaks_p3`, `number_of_peaks_p4`, `max_height_of_peaks_p1`, `max_height_of_peaks_p2`,\n",
    "`max_height_of_peaks_p4`, `max_height_of_peaks_p3`, `sum_spectrum_p1`, `max_spectrum_p1`, `mean_spectrum_p1`\n",
    "\n",
    "### Implementation\n",
    "\n",
    "The implementation process starts by extracting the features for each signal in the `train.parquet` file, as described before. Each signal needs to be denoised and then the features can be extracted. The signal denoising functions are in the `signal_denoising.py` file and the feature extraction in the `feature_extraction.py` file. This is the most time-consuming task, since each signal took around 0.5 seconds to be loaded and processed, thefore taking up to 1.2 hours to process all the signals in the training dataset (8712). This was done in the `execute_signal_processing.py` file, which will generate the output file `all_features.csv` with the extracted features. Next, this file is loaded and the feature scaling, transformation and selection are executed. This task, and the model learning are available in the `data_processing_and_modeling` Jupyter notebook.\n",
    "\n",
    "The remaining process is very straightforward, and consists in the following steps:\n",
    "* Load the dataset with the features already extracted transformed and selected into memory\n",
    "* Split the dataset into training (80%) and test (20%) sets\n",
    "* Evaluate several models using 10 fold cross-validation on the training set\n",
    "* Select the trained model with the highest MCC cross validation score\n",
    "* Train the selected model on training set\n",
    "    * Grid search will be used to select the optimal hyperparameters\n",
    "* Evaluate the model MCC score on the test set\n",
    "\n",
    "### Refinement\n",
    "\n",
    "As mentioned in the Benchmark section, the naive predictor achieved a poor MCC score of `0.0`. To get an initial result, a few models using default hyperparameters were tested agains the dataset: kNN, Gradient Boosting, Random Forest and Logistic Regression. The results can be seen on the boxplot below.\n",
    "\n",
    "![Model Cross-validation](model_cross_val_trial.png \"Model Cross-validation\")\n",
    "\n",
    "We can see that all the proposed models achieved a better score than our benchmark. Since the Random Forest model achieved a high score with only 10 trees in the forest, it will be selected as the model to be optimized. The grid search algorithm will be executed on the following hyperparameters configuration:\n",
    "\n",
    "* `n_estimators`: [10, 30, 50, 100, 150, 200, 300]\n",
    "* `max_features`: ['auto', 'sqrt']\n",
    "* `max_depth`: [10, 30, 50, 70, 100, None]\n",
    "* `min_samples_split`: [2, 5]\n",
    "* `min_samples_leaf`: [1, 2, 4]\n",
    "\n",
    "After executing the Grid Search for every combination of these parameters, the optimal model achieved a MMC score of `1.0` on the training set and `0.6` on the test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Results\n",
    "\n",
    "### Model Evaluation and Validation\n",
    "\n",
    "The final optimal hyperparameters for the random forest classifier are summarized below:\n",
    "\n",
    "* `n_estimators`: 200\n",
    "* `max_features`: 'auto'\n",
    "* `max_depth`: 30\n",
    "* `min_samples_split`: 5\n",
    "* `min_samples_leaf`: 1\n",
    "\n",
    "The model was chosen because it achieved the highest MCC score in the training data. The hyperparameters are also very reasonable, not having any very extreme values selected. To verify the robustness of the final model, the test data was evaluated, achieving a MCC score was `0.6`, which is a good value. However, it suggests that there was some overfitting on the training data, since the training score was `1.0`. \n",
    "\n",
    "### Justification\n",
    "\n",
    "Comparing to the benchmark model, the final solution was much better. The test MCC score values was increased from `0` to `0.6`, achieving the objective of this project. The figure below displays the confusion matrix of the test set evaluations.  \n",
    "\n",
    "![Confusion Matrix](cnf_matrix_testset.png \"Confusion Matrix\")\n",
    "\n",
    "The analysis of the confusion matrix shows that the model did a very good job classifying the normal signals. Its biggest challenge was to be able to correclty classify the faulted signals: only 48% of the examples were correctly classified as faulted, which was the reason the MMC score was not very high. This could be an effect of the very unbalanced dataset.\n",
    "\n",
    "The model was also evaluated against Kaggle's test set, achieving a score of `XXX`. This placed me among the top XX competitors, as of February 4th.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Conclusion\n",
    "\n",
    "### Free-Form Visualization\n",
    "\n",
    "The biggest challenge of this project is to find a representation of the PD signal that is good enough to separate between a faulted and normal signal. The figure below shows an example of signals classified as faulted and normal.\n",
    "\n",
    "![Fault and normal signals](signal_fault_normal_raw_freeform.png \"Fault and normal signals\")\n",
    "\n",
    "Visually, it is pratically impossible to classify each signal. In fact, the faulted signal has less peaks and is less noisy than the regular one! However, after applying feature extraction and data pre-processing techniques, it was possible to find relevant features that are able to separate them. This also summarizes a very interesting and exciting characteristic of this dataset: how a signal having 800,000 samples can be represented by only 11 features and be correclty classified only with this information. Furthermore, it higlights the importance of the data pre-processing in any data science project. \n",
    "\n",
    "### Reflection\n",
    "\n",
    "The process used for this project can be summarized using the following steps:\n",
    "\n",
    "1. An interesting and relevant problem with public data sets was found\n",
    "2. The data was downloaded, the signals denoised and the features extracted\n",
    "3. A benchmark was created for the classifier\n",
    "4. Several classifiers were evaluated and the best one selected\n",
    "5. The selected classifier was trained using the available train data, using grid search to optimize the hyperparameters\n",
    "6. The test data was evaluated against the optimal classifier\n",
    "7. The model predictions were submitted to the Kaggle website\n",
    "\n",
    "Step 2 was the most difficult and time-consuming task, because in order to correctly define the denoising and feature extraction techniques I had to study the available literature on PD signal processing. Since I already had a good background on the problem domain, I knew where to seek the necessary information and this became a very straight-forward task, even though being quite complex. I also decided to spend more time studying the feature selection and transformation, in order to polish my skills on these tasks and also produce a final dataset with better quality. In fact, this was the most interesting and important step in the project, since I could effectively see the impact of a good data preparation step on the model learning.  \n",
    "\n",
    "Steps 4 and 5 took less time than expected, since my choice of features proved to be good and the models achieved better results than the benchmark on the first trials. \n",
    "\n",
    "### Improvement\n",
    "\n",
    "To achive better results, I believe the first step is trying to improve the quality of the PD denoising and feature extraction algorithms. In [1], the author presents a series of signal representation techniques that can be used to extracted more relevant features from the PD signals. There are also a very large literature on PD denoising techniques, which could also be explored. Due to their complexity and the project's time constraints, I decided to only use the denoising and feature extraction techniques I was most familiar with.\n",
    "\n",
    "As for the models improvements, I believe it is worth exploring more the Gradient Boosting algorithm, since it also achieved good results on the initial trial and also works very well in practice. This could improve the overfitting observed on the training dataset and improve the current benchmark with random forests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
    "\n",
    "[2] S. Sriram, S. Nitin, K.M.M. Prabhu, and M.J. Bastiaans. Signal denoising techniques for\n",
    "partial discharge measurements. IEEE Transactions on Dielectrics and Electrical Insulation,\n",
    "12(6):1182–1191, 2005\n",
    "\n",
    "[3] Ma, X., Zhou, C. and Kemp, I.J., 2002. Interpretation of wavelet analysis and its application in partial discharge detection. IEEE Transactions on Dielectrics and Electrical Insulation, 9(3), pp.446-457.\n",
    "\n",
    "[4] S. Misák, J. Fulnecek, T. Vantuch, T. Buriánek and T. Jezowicz, \"A complex classification approach of partial discharges from covered conductors in real environment,\" in IEEE Transactions on Dielectrics and Electrical Insulation, vol. 24, no. 2, pp. 1097-1104, April 2017.\n",
    "\n",
    "[5] Liaw, A. and Wiener, M., 2002. Classification and regression by randomForest. R news, 2(3), pp.18-22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
